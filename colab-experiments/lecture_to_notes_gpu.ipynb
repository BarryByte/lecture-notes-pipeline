{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üéì Lecture to Notes - GPU Accelerated\n",
                "\n",
                "Transform long lecture videos (2-3 hours) into detailed, structured markdown notes using:\n",
                "- **Whisper Large-v3** for transcription (via faster-whisper)\n",
                "- **Qwen 2.5-14B** for intelligent note generation\n",
                "\n",
                "‚ö° **Requirements**: Google Colab with T4 GPU (free tier works!)\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1Ô∏è‚É£ Setup & Dependencies\n",
                "Run this cell first - takes ~2-3 minutes"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check GPU availability\n",
                "!nvidia-smi\n",
                "\n",
                "# Install dependencies\n",
                "!pip install -q faster-whisper transformers accelerate bitsandbytes sentencepiece\n",
                "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
                "\n",
                "print(\"\\n‚úÖ Dependencies installed!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2Ô∏è‚É£ Upload Your Lecture Video\n",
                "Supports MP4 files up to 600MB"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from google.colab import files\n",
                "import os\n",
                "\n",
                "print(\"üì§ Please upload your lecture video (MP4, max 600MB)...\")\n",
                "uploaded = files.upload()\n",
                "\n",
                "VIDEO_PATH = list(uploaded.keys())[0]\n",
                "VIDEO_NAME = os.path.splitext(VIDEO_PATH)[0]\n",
                "\n",
                "print(f\"\\n‚úÖ Uploaded: {VIDEO_PATH}\")\n",
                "print(f\"üìä Size: {os.path.getsize(VIDEO_PATH) / (1024*1024):.1f} MB\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3Ô∏è‚É£ Transcribe with Whisper Large-v3\n",
                "This uses faster-whisper for GPU-accelerated transcription"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from faster_whisper import WhisperModel\n",
                "import time\n",
                "\n",
                "print(\"üîÑ Loading Whisper Large-v3 model...\")\n",
                "model = WhisperModel(\"large-v3\", device=\"cuda\", compute_type=\"float16\")\n",
                "print(\"‚úÖ Model loaded!\")\n",
                "\n",
                "print(f\"\\nüé§ Transcribing: {VIDEO_PATH}\")\n",
                "print(\"‚è≥ This may take 5-15 minutes for a 2-3 hour video...\\n\")\n",
                "\n",
                "start_time = time.time()\n",
                "\n",
                "segments, info = model.transcribe(\n",
                "    VIDEO_PATH,\n",
                "    beam_size=5,\n",
                "    language=\"en\",\n",
                "    vad_filter=True,\n",
                "    vad_parameters=dict(min_silence_duration_ms=500)\n",
                ")\n",
                "\n",
                "# Collect all segments with timestamps\n",
                "transcript_segments = []\n",
                "full_transcript = \"\"\n",
                "\n",
                "for segment in segments:\n",
                "    transcript_segments.append({\n",
                "        \"start\": segment.start,\n",
                "        \"end\": segment.end,\n",
                "        \"text\": segment.text.strip()\n",
                "    })\n",
                "    full_transcript += segment.text + \" \"\n",
                "    \n",
                "    # Progress indicator\n",
                "    if len(transcript_segments) % 50 == 0:\n",
                "        print(f\"  Processed {len(transcript_segments)} segments...\")\n",
                "\n",
                "elapsed = time.time() - start_time\n",
                "print(f\"\\n‚úÖ Transcription complete!\")\n",
                "print(f\"‚è±Ô∏è Time taken: {elapsed/60:.1f} minutes\")\n",
                "print(f\"üìù Total segments: {len(transcript_segments)}\")\n",
                "print(f\"üìä Transcript length: {len(full_transcript.split())} words\")\n",
                "\n",
                "# Free up GPU memory\n",
                "del model\n",
                "import torch\n",
                "torch.cuda.empty_cache()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4Ô∏è‚É£ Load Qwen 2.5-14B for Note Generation\n",
                "Using 4-bit quantization to fit in T4 GPU memory"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
                "import torch\n",
                "\n",
                "MODEL_ID = \"Qwen/Qwen2.5-14B-Instruct\"\n",
                "\n",
                "print(f\"üîÑ Loading {MODEL_ID} with 4-bit quantization...\")\n",
                "print(\"‚è≥ This takes 3-5 minutes on first run...\\n\")\n",
                "\n",
                "# 4-bit quantization config\n",
                "bnb_config = BitsAndBytesConfig(\n",
                "    load_in_4bit=True,\n",
                "    bnb_4bit_quant_type=\"nf4\",\n",
                "    bnb_4bit_compute_dtype=torch.float16,\n",
                "    bnb_4bit_use_double_quant=True\n",
                ")\n",
                "\n",
                "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, trust_remote_code=True)\n",
                "llm_model = AutoModelForCausalLM.from_pretrained(\n",
                "    MODEL_ID,\n",
                "    quantization_config=bnb_config,\n",
                "    device_map=\"auto\",\n",
                "    trust_remote_code=True\n",
                ")\n",
                "\n",
                "print(\"‚úÖ LLM loaded and ready!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5Ô∏è‚É£ Generate Structured Notes\n",
                "Processing transcript in chunks for comprehensive notes"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def chunk_transcript(text, chunk_size=3000, overlap=200):\n",
                "    \"\"\"Split transcript into overlapping chunks for processing.\"\"\"\n",
                "    words = text.split()\n",
                "    chunks = []\n",
                "    start = 0\n",
                "    \n",
                "    while start < len(words):\n",
                "        end = min(start + chunk_size, len(words))\n",
                "        chunk = ' '.join(words[start:end])\n",
                "        chunks.append(chunk)\n",
                "        start = end - overlap if end < len(words) else end\n",
                "    \n",
                "    return chunks\n",
                "\n",
                "def generate_notes(text, section_num, total_sections):\n",
                "    \"\"\"Generate detailed notes for a transcript section.\"\"\"\n",
                "    \n",
                "    prompt = f\"\"\"You are an expert note-taker. Create detailed, comprehensive study notes from this lecture transcript section ({section_num}/{total_sections}).\n",
                "\n",
                "TRANSCRIPT:\n",
                "{text}\n",
                "\n",
                "Create notes following this structure:\n",
                "1. **Main Topics** - Key subjects covered\n",
                "2. **Detailed Explanations** - In-depth coverage of concepts\n",
                "3. **Key Definitions** - Important terms and their meanings\n",
                "4. **Examples Given** - Any examples or case studies mentioned\n",
                "5. **Important Points** - Crucial takeaways\n",
                "6. **Connections** - How topics relate to each other\n",
                "\n",
                "Be thorough and detailed. Use markdown formatting with headers, bullet points, and emphasis.\n",
                "Do NOT summarize - expand and explain the concepts clearly for study purposes.\"\"\"\n",
                "\n",
                "    messages = [\n",
                "        {\"role\": \"system\", \"content\": \"You are a meticulous academic note-taker who creates comprehensive, detailed study notes.\"},\n",
                "        {\"role\": \"user\", \"content\": prompt}\n",
                "    ]\n",
                "    \n",
                "    text_input = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
                "    inputs = tokenizer(text_input, return_tensors=\"pt\").to(\"cuda\")\n",
                "    \n",
                "    with torch.no_grad():\n",
                "        outputs = llm_model.generate(\n",
                "            **inputs,\n",
                "            max_new_tokens=4096,\n",
                "            temperature=0.7,\n",
                "            top_p=0.9,\n",
                "            do_sample=True,\n",
                "            pad_token_id=tokenizer.eos_token_id\n",
                "        )\n",
                "    \n",
                "    response = tokenizer.decode(outputs[0][inputs['input_ids'].shape[1]:], skip_special_tokens=True)\n",
                "    return response\n",
                "\n",
                "# Process transcript in chunks\n",
                "print(\"üìù Processing transcript and generating notes...\\n\")\n",
                "chunks = chunk_transcript(full_transcript)\n",
                "print(f\"üìä Split into {len(chunks)} sections for processing\\n\")\n",
                "\n",
                "all_notes = []\n",
                "for i, chunk in enumerate(chunks, 1):\n",
                "    print(f\"üîÑ Processing section {i}/{len(chunks)}...\")\n",
                "    notes = generate_notes(chunk, i, len(chunks))\n",
                "    all_notes.append(notes)\n",
                "    print(f\"   ‚úÖ Section {i} complete ({len(notes.split())} words)\")\n",
                "\n",
                "print(\"\\n‚úÖ All sections processed!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6Ô∏è‚É£ Generate Final Summary & Compile Notes"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def generate_executive_summary(notes_text):\n",
                "    \"\"\"Generate an executive summary of the entire lecture.\"\"\"\n",
                "    \n",
                "    # Take first 4000 words of notes for summary\n",
                "    summary_input = ' '.join(notes_text.split()[:4000])\n",
                "    \n",
                "    prompt = f\"\"\"Based on these lecture notes, create a comprehensive executive summary:\n",
                "\n",
                "{summary_input}\n",
                "\n",
                "Create:\n",
                "1. **Lecture Overview** (3-4 paragraphs)\n",
                "2. **Key Learning Objectives** (bullet points)\n",
                "3. **Main Topics Covered** (with brief descriptions)\n",
                "4. **Critical Takeaways** (most important points to remember)\n",
                "5. **Study Recommendations** (what to focus on for exams/understanding)\n",
                "\n",
                "Be comprehensive but concise.\"\"\"\n",
                "\n",
                "    messages = [\n",
                "        {\"role\": \"system\", \"content\": \"You are an expert at synthesizing academic content into clear summaries.\"},\n",
                "        {\"role\": \"user\", \"content\": prompt}\n",
                "    ]\n",
                "    \n",
                "    text_input = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
                "    inputs = tokenizer(text_input, return_tensors=\"pt\").to(\"cuda\")\n",
                "    \n",
                "    with torch.no_grad():\n",
                "        outputs = llm_model.generate(\n",
                "            **inputs,\n",
                "            max_new_tokens=2048,\n",
                "            temperature=0.7,\n",
                "            top_p=0.9,\n",
                "            do_sample=True,\n",
                "            pad_token_id=tokenizer.eos_token_id\n",
                "        )\n",
                "    \n",
                "    return tokenizer.decode(outputs[0][inputs['input_ids'].shape[1]:], skip_special_tokens=True)\n",
                "\n",
                "# Combine all notes\n",
                "combined_notes = \"\\n\\n\".join(all_notes)\n",
                "\n",
                "print(\"üìã Generating executive summary...\")\n",
                "executive_summary = generate_executive_summary(combined_notes)\n",
                "print(\"‚úÖ Summary generated!\")\n",
                "\n",
                "# Compile final document\n",
                "from datetime import datetime\n",
                "\n",
                "final_notes = f\"\"\"# üìö {VIDEO_NAME}\n",
                "\n",
                "**Generated**: {datetime.now().strftime('%Y-%m-%d %H:%M')}\n",
                "**Source**: {VIDEO_PATH}\n",
                "**Duration**: ~{len(transcript_segments) * 3 // 60} minutes (estimated)\n",
                "**Model**: Qwen 2.5-14B + Whisper Large-v3\n",
                "\n",
                "---\n",
                "\n",
                "# üìã Executive Summary\n",
                "\n",
                "{executive_summary}\n",
                "\n",
                "---\n",
                "\n",
                "# üìù Detailed Notes\n",
                "\n",
                "\"\"\"\n",
                "\n",
                "for i, notes in enumerate(all_notes, 1):\n",
                "    final_notes += f\"\\n## Part {i}\\n\\n{notes}\\n\\n---\\n\"\n",
                "\n",
                "# Add transcript reference at the end\n",
                "final_notes += f\"\"\"\n",
                "# üìú Full Transcript\n",
                "\n",
                "<details>\n",
                "<summary>Click to expand full transcript ({len(full_transcript.split())} words)</summary>\n",
                "\n",
                "{full_transcript}\n",
                "\n",
                "</details>\n",
                "\"\"\"\n",
                "\n",
                "print(f\"\\nüìä Final notes: {len(final_notes.split())} words\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7Ô∏è‚É£ Save & Download Notes"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save to file\n",
                "output_filename = f\"{VIDEO_NAME}_notes.md\"\n",
                "\n",
                "with open(output_filename, 'w', encoding='utf-8') as f:\n",
                "    f.write(final_notes)\n",
                "\n",
                "print(f\"‚úÖ Notes saved to: {output_filename}\")\n",
                "print(f\"üìä File size: {os.path.getsize(output_filename) / 1024:.1f} KB\")\n",
                "\n",
                "# Download the file\n",
                "print(\"\\nüì• Downloading notes file...\")\n",
                "files.download(output_filename)\n",
                "\n",
                "print(\"\\nüéâ Done! Your detailed lecture notes are ready.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üîß Optional: Save Transcript Separately"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save timestamped transcript\n",
                "transcript_filename = f\"{VIDEO_NAME}_transcript.txt\"\n",
                "\n",
                "with open(transcript_filename, 'w', encoding='utf-8') as f:\n",
                "    for seg in transcript_segments:\n",
                "        mins = int(seg['start'] // 60)\n",
                "        secs = int(seg['start'] % 60)\n",
                "        f.write(f\"[{mins:02d}:{secs:02d}] {seg['text']}\\n\")\n",
                "\n",
                "print(f\"‚úÖ Transcript saved to: {transcript_filename}\")\n",
                "files.download(transcript_filename)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## ‚è±Ô∏è Expected Processing Times\n",
                "\n",
                "| Video Length | Transcription | Note Generation | Total |\n",
                "|-------------|---------------|-----------------|-------|\n",
                "| 1 hour | ~3-5 min | ~5-8 min | ~10-15 min |\n",
                "| 2 hours | ~6-10 min | ~10-15 min | ~20-25 min |\n",
                "| 3 hours | ~10-15 min | ~15-20 min | ~30-40 min |\n",
                "\n",
                "**Note**: First run takes longer due to model downloads (~10-15 min additional)."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
